= Module 2: Service Mesh Integration with Virtual Machines

include::vars.adoc[]

In this module we are going to introduce *Red Hat OpenShift Service Mesh* and explore the added features and capabilities, that allow us to elevate the experience of operating and monitoring Virtual Machines(VMs) as first class citizens in a cloud-native world.  


## Objectives

* Introducing OpenShift Service Mesh
* Integrate VMs with OpenShift Service Mesh for advanced networking
* Implement traffic management rules and review new observability features through OSSM
* Configure Advanced Security and Testing with Virtual Machines

[[about-service-mesh]]
== About OpenShift Service Mesh

image::01-OSSM-ServiceMesh.png[link="self", window=blank, width="100%"]

Red Hat OpenShift Service Mesh is an integrated service mesh solution based on the open source projects **Istio**, **Kiali**, and **Jaeger**, designed to simplify microservice communication, security, and observability in OpenShift environments. It provides a uniform way to manage service-to-service interactions, including *traffic control*, *security policies*, and *monitoring*.

NOTE: OpenShift https://www.redhat.com/en/topics/microservices/what-is-a-service-mesh[Service Mesh,window=_blank] is an add-on service that can be installed through an operator.

Even though OpenShift Service Mesh is primarily designed for containerized workloads, it also supports VMs by integrating them into the mesh. Key benefits for VMs include:

* *Consistent Networking & Security* – VMs can securely communicate with containerized workloads using mTLS encryption and access policies.
* *Unified Observability* – VMs gain visibility through tracing (Jaeger), monitoring (Prometheus, Grafana), and service topology visualization (Kiali).
* *Traffic Management* – Enables intelligent routing, load balancing, and failover between VMs and microservices.
* *Gradual Migration* – Allows a hybrid approach, where legacy VMs can coexist and gradually transition into a containerized environment.
* *Policy Enforcement* – Ensures compliance by applying service-level access control and security policies uniformly across VMs and containers.

The following section provides additional information on the Service Mesh Architecture. *Feel free to skip the following section to save time* and come back later if needed.

=== OpenShift Service Mesh Architecture

image::02-OSSM-Components.png[link="self", window=blank, width="100%"]

OpenShift Service Mesh, delivered as part of the platform, adds the above cross-cutting application capabilities through the following components:

* *istiod*: applies all defined policies (encryption, authorization, traffic management, observability) in the network of VMs and containers included in the mesh.
* *envoy*: a sidecar container, of a VM or containerized workload, with the ability to receive and apply the policies effectively making a VM part of the mesh. The envoy sits side-by-side to a VM (see the image above) and intercepts all requests coming in and out of it.
* *Kiali*: visualises through a UI what is configured in the mesh, the network of included applications, the traffic througput and latency, the security utilised, the issues that may occur in the configurations or netwrork, the logs and a host of other features that the mesh offers.
* The rest of the observbility components (as seen in the image above) contain parts of what `kiali` visualises for a deeper inspection:
** `Prometheus` collects the _metrics_ emitted by the `envoy` of each container/VM in the mesh, 
** `Grafana` provides additional dashboards for the operators and business analysts to review on performance, request throughput/latency, success/failures etc.
* *Gateways*: one or more `ingress gateway` instances support traffic flow into service mesh from the outside. This is required since the mesh comes with `network policies` that disable direct access to VMs/containers in the mesh. Also an `egress gateway` respectively can control outgoing traffic from the mesh to external services.

NOTE: The administrators of the cluster you will be using have already done the setup of Service Mesh so lets see how easy it is to enable a a VM to take advantage of these new capabilities.


== Getting Started

NOTE: All assets for this module are in the folder `module-02` in the repo you cloned in the introduction module. Please change the directory into this folder now.

[,sh,subs="attributes",role=execute]
----
cd $HOME/modernize-ocp-virt-workspace/module-02
----

[[explore-service-mesh]]
== Explore the Service Mesh Observability Stack

Beginning with Red Hat OpenShift Service Mesh 3, the various components that make up the service mesh functionality as outlined above are integrated into the left hand menu bar through dynamic plugins.

Older versions would require that each of the individual services **Istio**, **Kiali**, and **Grafana** be exposed through their own routes, and be made accessible through a console login. The newer version is much more streamlined and easier for users to begin working with.


== Explore the Service Mesh Console Plugin

Click on `Service Mesh -> Overview` in the left side navigation menu to see a screen that shows information about each Red Hat OpenShift project, and the applications hosted there. As you can see that 


Leave the `Kiali` dahsboard in your browser and proceed to the next task.

CAUTION: Why can't you see any services?

*Despite the lack of data you have been successful!* You have now successfully accessed and explored the additional observability tools provided by OpenShift Service Mesh.  

[[add-service-mesh]]
== Add VMs & Containers to OpenShift Service Mesh

If it was not apparent until now, you can only apply policies (security, observability etc.) to VMs and containers that are part of the mesh!

IMPORTANT: In order to become part of the mesh each _Travel Booking_ namespace must be configured to be a *member of the mesh*, and each workload component needs to have an *additional _sidecar container_ injected*, which will intercept the traffic to/from your VM. 

Take a look at the pods that are associated with the VMs that are in your {modernize_ocp_virt_username}-travel-agency project by clicking on Workloads -> Pods, and selecting {modernize_ocp_virt_username}-travel-agency from the dropdown *Project* menu. 

image::rh1/200-mod2-travel-agency-pods.png[link=self, window=blank, width="100%"]

Right now you may notice that the pods associated with each VM have but a *single container!*

image::06-t2-ossm-travel-agency-1-container.png[link=self, window=blank, width="100%"]
image::06-t2-ossm-travel-control-1-container.png[link=self, window=blank, width="100%"]

Lets add the _Travel Booking_ application to the service mesh. 

We do this by adding a sidecar container to each of the workloads (VMs and containers).

This forms the actual dataplane of the mesh, and consists of an `envoy-proxy` (namely the `istio-proxy` container).

The provided scripts will insert the injection annotation `sidecar.istio.io/inject` in each workload and also restart them, so that service mesh can inject the `istio-proxy` container and start applying the configured policies.

Execute in the *Terminal* the following scripts:

[,sh,subs="attributes",role=execute]
----
./add-envoy-to-travel-agency-services-domain.sh
----

[,sh,subs="attributes",role=execute]
----
./add-envoy-to-travel-portal-domain.sh
----

[,sh,subs="attributes",role=execute]
----
./add-envoy-to-travel-control.sh
----

NOTE: For details of how this is done see the scripts at {modernize_ocp_virt_repo}/blob/main/module-02/add-envoy-to-travel-agency-services-domain.sh[add-envoy-to-travel-agency-services-domain.sh, window=_blank], {modernize_ocp_virt_repo}/blob/main/module-02/add-envoy-to-travel-portal-domain.sh[add-envoy-to-travel-portal-domain.sh, window=_blank], {modernize_ocp_virt_repo}/blob/main/module-02/add-envoy-to-travel-control.sh[add-envoy-to-travel-control.sh, window=_blank]. 

Now we have included all _Travel Booking_ VMs and Containers in the mesh, and each POD is made up of 2 containers (the `workload` and the `istio-proxy` container)

image::06-2-containers.gif[link=self, window=blank]

*This is it!!* The VMs can now take advantage of all the service mesh features.

[[validate-apps]]
== Validate Service Mesh Enabled Applications

### Mesh Visualization in Kiali Console 
Go back to the `Kiali` Dashboard. 

We are now able to visualise network information about the _Travel Booking_ services. 

TIP: `Kiali` can give you a lot more than just visualisation of the network. You can review the applied mesh configurations, modify them or apply new ones.

====
In the `Kiali` Dashboard, click the *Select All* option, from the *Select Namespace* drop-down menu (at the top). You should now see 3 _Travel Booking_ namespaces listed. 
====

====
The `Versioned App Graph` shows the whole network of microservices (VMs and containers) and the traffic flowing between them.

image::06-t2-ossm-travel-agency.gif[link=self, window=blank]
====

IMPORTANT: Wow this is truly brilliant. Containers and VMs working side by side within the platform and the mesh is integrating them without distinguishing on the technology of their runtime. You only had to make 1 annotation change to the VM resource.

NOTE: You can explore additional features of Kiali in the optional Task 5.

### Grafana Dashboards

====
Finally, go back to the `Grafana dashboard`.

The _Istio Mesh Dashboard_ now has been populated with information about the application that you can use to undertand the healthiness, content and usage of the solution.

image::10-t2-grafana-mesh-dashboard-with-data.png[Istio Mesh Dashboard]
====

NOTE: *Congratulations for making it through all the steps!!!* That was a lot of information and they are at the operator's fingertips with one simple annotation insertion.

## Task 4: Expose the _Travel Booking_ VM

Have you noticed that you are still not able to access the _Travel Booking_ application UI?

It's because there is no route configured to expose the services to the outside world.

Since, the user interface is not accessible yet, we will test the solution through internal service-to-service communications. We are going to simulate a booking request by sending a request for a travel quote from the `travels` portal in the `{modernize_ocp_virt_username}-travel-portal` namespace to the `travels-vm` VM in the `{modernize_ocp_virt_username}-travel-agency` namespace:

[,sh,subs="attributes",role=execute]
----
oc -n {modernize_ocp_virt_username}-travel-portal exec $(oc -n {modernize_ocp_virt_username}-travel-portal get po -l app=travels|awk '{print $1}'|tail -n 1) -- curl -s travels-vm.{modernize_ocp_virt_username}-travel-agency.svc.cluster.local:8000/travels/London |jq
----

You should receive a quote similar to the one following:

[source,yaml,subs=attributes]
----
{
  "city": "London",
  "coordinates": null,
  "createdAt": "2025-03-24T13:58:06Z",
  "status": "Valid",
  "flights": [
    {
      "airline": "Red Airlines",
      "price": 1018
    },
    {
      "airline": "Blue Airlines",
      "price": 368
    },
    {
      "airline": "Green Airlines",
      "price": 318
    }
  ],
  "hotels": [
    {
      "hotel": "Grand Hotel London",
      "price": 590
    },
    {
      "hotel": "Little London Hotel",
      "price": 116
    }
  ],
  "cars": [
    {
      "carModel": "Sports Car",
      "price": 1090
    },
    {
      "carModel": "Economy Car",
      "price": 336
    }
  ],
  "insurances": [
    {
      "company": "Yellow Insurances",
      "price": 325
    },
    {
      "company": "Blue Insurances",
      "price": 74
    }
  ]
}
----

We will now use the Service Mesh and the Kubernetes Gateway API to expose the `control-vm` service where you will get to see the Travel Control dashboard.

There is an Istio Gateway already deployed in the istio-gateway namespace, and an external Route in that namespace exposing the gateway to outside traffic. In this exercise you will create an HTTPRoute (Gateway API) that attaches to that existing gateway and forwards HTTP requests to the control-vm service.

[,bash,subs="attributes",role=execute]
----
echo "apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: control-vm-httproute
  namespace: {modernize_ocp_virt_username}-travel-control
spec:
  parentRefs:
  - name: gateway-shared
    namespace: istio-gateway
  hostnames:
  - "{modernize_ocp_virt_username}-istio-gateway.{modernize_ocp_virt_apps_domain}"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: control-vm
      port: 8080" | oc apply -f -
----

If everything is correct, you should now be able to access the Travel Control dashboard through the gateway.

Click on the link here: https://{modernize_ocp_virt_username}-istio-gateway.{modernize_ocp_virt_apps_domain}[Travel Control Dashboard^]

[[canary-release]]
== Versioning VMs with a Canary Release

Often you will be required to deploy and maintain multiple versions of an application to provide new features to a subset of customers. 

. In this Task, you will be releasing a new version *v2* of the *cars-vm* component, allowing *10%* of new customers to access this new service, whilst the remainder will continue to use version *v1*. 

. If everything goes well, you will gradualy increase up to *80%* of the traffic to version *v2*.

. In order to achieve this, you are going to deploy a new VM with the name `cars-vm-v2` and a label `version=v2`

. Then you need to configure a `DestinationRule` to be able to direct the traffic to both versions of the `cars-vm` service.

. Finally, you will create a `VirtualService` to split the traffic between the 2 versions according to the defined percentages.

. For more details, find the manifests used {modernize_ocp_virt_repo}/blob/main/module-03/multipleversions-for-car-vm-in-the-mesh.sh[here,window=_blank].

NOTE: You could also use `Kiali` to define the configurations. In this case we are using a script.

Now execute the script below which delivers all the above configurations:

[,sh,subs="attributes",role=execute]
----
./multipleversions-for-car-vm-in-the-mesh.sh 90 10
----

====
Go to your `Kiali` Dashboard.

Click on *Istio Config*. This will now list the new traffic management configurations under the `travel-agency` namespace.

image::01-m4-t1-kiali-config.png[link=self, window=blank]
====

====
Shortly after creating the traffic configuration you will start seeing the result of the traffic split in the `Kiali` graph as the following animated image also shows. The 2 drop-down menus (top right) can define the graph refreshing periods.

NOTE: Select *Display -> Traffic Distribution* from the drop down menu to visualise the traffic percentages.

image::02-m4-t2-separate-v1-v2-traffic.gif[link=self, window=blank]
====

After you have verified the new version is stable go ahead and increase the traffic routing for version `v2` to `80%`.

[,sh,subs="attributes",role=execute]
----
./multipleversions-for-car-vm-in-the-mesh.sh 20 80
----

====
The *Istio config* in `Kiali` has been updated (see https://kiali-istio-system.{modernize_ocp_virt_apps_domain}/console/namespaces/travel-agency/istio/virtualservices/cars[cars `VirtualService`, window=_blank]) and soon the Graph should show `80%` traffic flowing to version `v2`. 
====

[[auth-policies]]
== Access Limitations with Authorization Policies

Although security features such as *traffic encryption* are by default applied in the mesh, other practices such as access rules on what is a service's visibility and who can access them are not applied by default. This can have a two-fold effect:

* Services that are bad actors deployed by 3rd party in the cluster can gain access to a sensitive service,
* The amount of all possible destinations in a very large cluster can make the configuration of `istio-proxy` sidecar very large, causing evictions and possible cluster instability.

In order to counter these possible issues, you can apply `AuthorizationPolicy` resources and visibility restrictions based on the principal (the service identification) included in the exchanged certificate.

[NOTE]
====
++++
<details>
  <summary style=""><b>About Authorization Policies</b></summary>
  <p style="color:black;">The authorization policy enforces access control to the inbound traffic in the server side Envoy proxy. Each Envoy proxy runs an authorization engine that authorizes requests at runtime. When a request comes to the proxy, the authorization engine evaluates the request context against the current authorization policies, and returns the authorization result, either <b>ALLOW</b> or <b>DENY</b>. Operators specify Istio authorization policies using <b>YAML</b> notation. </</p>
</details>
++++
====

First you apply a https://istio.io/latest/docs/ops/best-practices/security/#use-default-deny-patterns[default deny all, window=_blank] policy which is a best practise. 

[,sh,subs="attributes",role=execute]
----
echo "apiVersion: security.istio.io/v1
kind: AuthorizationPolicy
metadata:
  name: allow-nothing
  namespace: {modernize_ocp_virt_username}-travel-agency
spec:
  {}" | oc apply -f -
----

[,sh,subs="attributes",role=execute]
----
echo "apiVersion: security.istio.io/v1
kind: AuthorizationPolicy
metadata:
  name: allow-nothing
  namespace: {modernize_ocp_virt_username}-travel-control
spec:
  {}" | oc apply -f -
----

Now all services of the _Travel Booking_ application stop communicating with each other as they no longer have permission to do so (see also `Kiali` Graph for the failures). 

NOTE: You can confirm the effect by accessing the https://{modernize_ocp_virt_username}-istio-gateway.{modernize_ocp_virt_apps_domain}/[Travel Booking Dashboard, window=_blank] which now returns `RBAC: access denied`.

[IMPORTANT]
====
Next apply (in the *Terminal*) 2 fine grained `AuthorizationPolicy` resources which will allow communications between: 

* The `istio-gateway` *->* `control-vm`, 
* From services in the `{modernize_ocp_virt_username}-travel-portal` *->* to services in `{modernize_ocp_virt_username}-travel-agency`, and 
====

[,sh,subs="attributes",role=execute]
----
echo "apiVersion: security.istio.io/v1
kind: AuthorizationPolicy
metadata:
  name: allow-selective-principals-travel-control
  namespace: {modernize_ocp_virt_username}-travel-control
spec:
  action: ALLOW
  rules:
  - from:
    - source:
        principals: [\"cluster.local/ns/istio-gateway/sa/gateway-shared-istio\"]" | oc apply -f -
----

[,sh,subs="attributes",role=execute]
----
echo "apiVersion: security.istio.io/v1
kind: AuthorizationPolicy
metadata:
  name: allow-selective-principals-travel-agency
  namespace: {modernize_ocp_virt_username}-travel-agency
spec:
  action: ALLOW
  rules:
  - from:
    - source:
        principals: [\"cluster.local/ns/{modernize_ocp_virt_username}-travel-agency/sa/default\",\"cluster.local/ns/{modernize_ocp_virt_username}-travel-portal/sa/default\"]" | oc apply -f -
----

====
After a short period you should gain access to the https://{modernize_ocp_virt_username}-istio-gateway.{modernize_ocp_virt_apps_domain}/[Travel Booking Dashboard, window=_blank] and the `Kiali` dashboard will show a restored network of communications between the services.
====

However, the communication between the `travel-control` and `travel-agency` services has been restricted as it is unnecessary and the applied `AuthorizationPolicy` rule does not permit it.

You can test this by executing the following command in the terminal:

[,sh,subs="attributes",role=execute]
----
oc -n {modernize_ocp_virt_username}-travel-control run toolbox --rm -it --image=registry.redhat.io/rhel9/toolbox --restart=Never -- curl -o - -I travels-vm.{modernize_ocp_virt_username}-travel-agency.svc.cluster.local:8000/travels/London
----

You should receive a response that this operation is forbidden.

[source,yaml,subs=attributes]
----
HTTP/1.1 403 Forbidden
content-length: 19
content-type: text/plain
date: Mon, 24 Mar 2025 16:10:11 GMT
server: envoy
x-envoy-upstream-service-time: 1
----

## Congratulations on completing this module!


You have come a long way to create a more secure and robust solution for the _Travel Agency_ company. 

You have explored VMs in OpenShift, used Service Mesh for Observability, traffic management, canary rollouts and security enhancements and also scaled virtual machines. 

IMPORTANT: All of this has been achieved without modifying anything inside the VMs!

In the next scenario you will be automating the delivery of these configurations so that they can be monitored and applied as your needs change in a declarative rather than imperative manner by using _OpenShift GitOps_.

== Summary

*Congratulations!!* on completing this module,

In this module you have introduced the _Travel Booking_ namespaces, containers and VMs to service mesh, reviewed all the observability tooling on offer from OpenShift Service Mesh and by now have an understanding of how sidecars configure cross-cutting features of security, traffic and monitoring without altering the internal application components whether these are VMs or containers. 

The ease with which a VM can be enhanced with features of cross-cutting concern (security, observability) in a cloud native world is the most appealing aspect of all. 
